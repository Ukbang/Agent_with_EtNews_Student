{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "from typing import Annotated, Literal\n",
    "from typing_extensions import TypedDict\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langgraph.graph import StateGraph, START, END\n",
    "from langgraph.graph.message import add_messages\n",
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "from langchain_core.prompts import ChatPromptTemplate, PromptTemplate\n",
    "from langchain_core.runnables import RunnableConfig\n",
    "from langchain_experimental.tools.python.tool import PythonAstREPLTool\n",
    "from pydantic import BaseModel, Field\n",
    "import dotenv\n",
    "import os\n",
    "\n",
    "dotenv.load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = # 타이타닉 데이터셋의 루트를 지정해주세요.\n",
    "df = # 타이타닉 데이터셋을 불러와주세요.\n",
    "\n",
    "llm = # OpenAI모델을 불러와주세요.\n",
    "\n",
    "tool = PythonAstREPLTool(name=\"python_repl_ast\", \n",
    "                        description=\"Python Code interpreter\",\n",
    "                        locals={\"df\":df})    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class State(TypedDict):\n",
    "    messages : Annotated[list, add_messages]\n",
    "    code : Annotated[str, \"Python Code\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_title_summary(df):\n",
    "\n",
    "    df_sampled = df.sample(n=5000) if len(df) > 5000 else df\n",
    "\n",
    "    prompt = PromptTemplate.from_template(\"\"\"\n",
    "            당신은 요약 전문가입니다.\n",
    "           \n",
    "            데이터셋 : {df}\n",
    "\n",
    "            데이터셋의 정보를 보고 제목과 요약을 만들어냅니다.\n",
    "            제목은 이 데이터셋을 가장 잘 표현할 수 있는 제목으로 결정하여야합니다.\n",
    "\n",
    "            참고할 정보는 아래와 같습니다.\n",
    "            \"\"\"\n",
    "            f\"\"\"                                          \n",
    "            파일 이름 : {file_path.split(\"/\")[-1]}\n",
    "\n",
    "            1. 제목: \n",
    "            2. 요약: \n",
    "\n",
    "            \"\"\"\n",
    "            )\n",
    "    \n",
    "    chain = prompt | llm\n",
    "    \n",
    "    result = chain.invoke({\"df\":df_sampled}).content\n",
    "\n",
    "    title = \"Untitled\"\n",
    "    summary = \"No Summary\"    \n",
    "\n",
    "    try:\n",
    "        lines = result.split(\"\\n\")\n",
    "        title = lines[0].replace(\"1. 제목: \", \"\").strip()\n",
    "        summary = \"\\n\".join(lines[1:]).replace(\"2. 요약:\", \"\").strip()\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "    print(\"===== 제목, 요약 생성 완료 =====\\n\\n\")\n",
    "    \n",
    "    return title, summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "title, summary = create_title_summary(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"제목 : \", title)\n",
    "print(\"요약 : \", summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Discriminator(BaseModel):\n",
    "    \"\"\"\n",
    "    주어진 데이터와 관련이 있는 정보인지 판단하고 분석을 할 준비를 진행합니다.\n",
    "    데이터와 관련이 있는 질문이라면 \"yes\", 아니라면 \"no\"라고 답변하세요.\n",
    "    \"\"\"\n",
    "\n",
    "    binary : Literal[\"yes\", \"no\"] = Field(..., description=\"\"\"\n",
    "                                          Determine if the information is relevant to the given data and prepare for analysis.\n",
    "                                          Answer \"yes\" if the questions are related to the data, and \"no\" if the questions can only be answered with existing knowledge.\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "discriminator = ChatOpenAI(model=\"gpt-4o-mini\",\n",
    "                          temperature=0.,).with_structured_output(Discriminator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Judge(BaseModel):\n",
    "    \"\"\"\n",
    "    당신은 AI에이전트입니다.\n",
    "    가지고 있는 도구는 아래와 같습니다.\n",
    "\n",
    "    1. PythonAstREPLTool : 텍스트로 된 파이썬 코드를 실행시킬 수 있는 도구\n",
    "\n",
    "    입력된 값을 기준으로 판단했을 때 도구를 실행시켜야하는 경우라면 'tool', 코드를 실행시키지 않아도 되는 경우에는 'llm'이라고 답변하세요.\n",
    "    \"\"\"\n",
    "\n",
    "    select_tool : Literal[\"tool\", \"llm\"] = Field(..., description=\"\"\"\n",
    "                                                 You are an AI agent.\n",
    "                                                 The tools you have are as follows.\n",
    "                                                 \n",
    "                                                 1. Python AstREPLTool: a tool that allows you to run textual Python code\n",
    "                                                 \n",
    "                                                 Answer 'tool' if you need to run the tool based on the input value, or 'llm' if you don't need to run the code.\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "judge = ChatOpenAI(model=\"gpt-4o-mini\",\n",
    "                          temperature=0.,).with_structured_output(Judge)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Discriminate(state:State):\n",
    "\n",
    "    \"\"\"\n",
    "    데이터셋과 관련이 있는지 판단하는 함수\n",
    "    \"\"\"\n",
    "\n",
    "    prompt = ChatPromptTemplate.from_messages([\n",
    "        (\"system\",\"\"\"df : {df}\n",
    "                    title : {title}\n",
    "                    summary : {summary}\"\"\"),\n",
    "        (\"human\", \"query : {query}\")\n",
    "    ])\n",
    "\n",
    "    chain = prompt | discriminator\n",
    "\n",
    "    result = chain.invoke({\"df\":df.head(),\n",
    "                           \"title\":title,\n",
    "                           \"summary\":summary,\n",
    "                           \"query\":state[\"messages\"][-1]}).binary\n",
    "    \n",
    "    global snapshot\n",
    "    snapshot = result\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Judgement(state:State):\n",
    "\n",
    "    \"\"\"\n",
    "    코드 실행이 필요한지 판단하는 함수\n",
    "    \"\"\"\n",
    "\n",
    "    prompt = ChatPromptTemplate.from_messages([\n",
    "        (\"system\",\"\"\" 당신은 10년차 데이터 분석 전문가 및 해결사입니다.\n",
    "                    질문의 결과를 위해 코드 실행이 필요한지 여부를 판단해야합니다.\n",
    "                    그 판단을 위해 당신에겐 샘플 데이터가 주어집니다.\n",
    "                    코드 실행이 필요하지 않다면 \"llm\"이라고 답변하세요.\n",
    "                    하지만, 코드 실행을 해야한다면 \"tool\"을 반환합니다.\n",
    "                    \n",
    "                    ### 샘플 데이터\n",
    "                    title : {title}\n",
    "                    summary : {summary}\n",
    "                    \n",
    "                    df : {df}\n",
    "                    ---\n",
    "\n",
    "                \"\"\"),\n",
    "        (\"human\", \"query : {query}\")\n",
    "    ])\n",
    "\n",
    "    chain = prompt | judge\n",
    "\n",
    "    result = chain.invoke({\"title\":title,\n",
    "                            \"summary\":summary,\n",
    "                            \"df\" : df.head(),\n",
    "                            \"query\":state[\"messages\"][-1]}).select_tool\n",
    "\n",
    "    global snapshot\n",
    "    snapshot = result\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_code(state:State):\n",
    "    \n",
    "    prompt = ChatPromptTemplate([\n",
    "        (\"system\", \"\"\"당신은 pandas, matplotlib 라이브러리를 사용할 수 있는 전문가입니다. 주어진 df의 형태를 참고하여 코드를 작성합니다. \\\n",
    "                    다음은 `print(df.head())`의 형태입니다. {head}\n",
    "        \n",
    "                    ### 예시1\n",
    "                    ```python\n",
    "        \n",
    "                    len(df)\n",
    "                    ```\n",
    "                    ### 예시2\n",
    "                    ```python\n",
    "        \n",
    "                    # sum_gamerounds에 대한 히스토그램\n",
    "                    plt.figure(figsize=(12, 6))\n",
    "                    plt.hist(df['sum_gamerounds'], bins=10, edgecolor='black')\n",
    "                    plt.title('Distribution of Sum Gamerounds')\n",
    "                    plt.xlabel('Sum Gamerounds')\n",
    "                    plt.ylabel('Frequency')\n",
    "                    plt.grid()\n",
    "                    plt.show()\n",
    "                    ```\n",
    "         \n",
    "                    ### 주의할 점\n",
    "                    1. seaborn은 사용하지 않습니다.\n",
    "        \n",
    "        \"\"\"),\n",
    "        (\"human\", \"{query}\")\n",
    "    ])        \n",
    "    \n",
    "    chain = prompt | llm\n",
    "\n",
    "    result = chain.invoke({\n",
    "        \"head\" : df.head(),\n",
    "        \"query\" : state[\"messages\"][-1]\n",
    "    }).content\n",
    "\n",
    "    try:\n",
    "        code = re.findall(r'```python\\n(.*?)\\n```', result, re.DOTALL)[0]\n",
    "\n",
    "        return # code를 반환해주세요.\n",
    "    except:\n",
    "        return # messages와 code를 반환해주세요. messages의 변경값은 result, code의 변경값은 \"\" 입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def execute_code(state:State):\n",
    "    # 코드 실행 함수를 만들어주세요.\n",
    "\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def response(state:State):\n",
    "\n",
    "    \"\"\"\n",
    "    답변 함수입니다.\n",
    "    \"\"\"\n",
    "\n",
    "    if snapshot == \"no\":\n",
    "        \"\"\"\n",
    "        데이터와 관련이 없는 질문일 때 오는 분기\n",
    "        \"\"\"\n",
    "\n",
    "        prompt = # 프롬프트를 입력해주세요.\n",
    "\n",
    "        chain = # 체인을 구성해주세요.\n",
    "\n",
    "        answer = # 체인을 실행시켜주세요.\n",
    "        \n",
    "        return # messages로 answer를 반환합니다.\n",
    "    \n",
    "    elif snapshot == \"llm\":\n",
    "        \"\"\"\n",
    "        데이터와 관련은 있으나 코드 실행과는 무관한 질문일 때 오는 분기\n",
    "        \"\"\"\n",
    "\n",
    "        prompt = ChatPromptTemplate([\n",
    "            (\"system\", \"\"\"\n",
    "             \n",
    "             # 프롬프트를 작성해주세요.\n",
    "            \n",
    "             제목 : {title}            \n",
    "             요약 : {summary}\n",
    "\n",
    "             df : {df}\n",
    "            \n",
    "            \"\"\"),\n",
    "            (\"human\", \"{query}\")\n",
    "        ])        \n",
    "        \n",
    "        chain = prompt | llm\n",
    "\n",
    "        answer = chain.invoke({\n",
    "            \"title\" : title,\n",
    "            \"summary\" : summary,\n",
    "            \"df\" : df,\n",
    "            \"query\" : state[\"messages\"][-1]\n",
    "        })\n",
    "\n",
    "        return {\"messages\":answer}\n",
    "    \n",
    "    else:\n",
    "        raise Exception(\"알 수 없는 응답입니다.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def code_response(state:State):\n",
    "\n",
    "    if state[\"code\"] == \"\":\n",
    "\n",
    "        \"\"\"\n",
    "        코드 추출에 실패했을 때 실행되는 분기\n",
    "        \"\"\"\n",
    "\n",
    "        prompt = ChatPromptTemplate([\n",
    "            (\"system\", \"\"\" \n",
    "             당신은 인사이트를 제공해주는는 데이터 분야 10년차 전문가입니다.\n",
    "             이전 답변과 정보를 기반으로 질문에 대해 답변합니다.\n",
    "            \n",
    "             제목 : {title}            \n",
    "             요약 : {summary}\n",
    "\n",
    "             답변 : {answer}\n",
    "            \n",
    "            \"\"\"),\n",
    "            (\"human\", \"{query}\")\n",
    "        ])        \n",
    "        \n",
    "        chain = prompt | llm\n",
    "\n",
    "        answer = chain.invoke({\n",
    "            \"title\" : title,\n",
    "            \"summary\" : summary,\n",
    "            \"answer\" : state[\"messages\"][:-1],\n",
    "            \"query\" : state[\"messages\"][-1]\n",
    "        })\n",
    "\n",
    "        return {\"messages\" : answer}\n",
    "\n",
    "    else:\n",
    "        \"\"\"\n",
    "        코드 추출에 성공했을 때 실행되는 분기\n",
    "        \"\"\"\n",
    "\n",
    "        prompt = ChatPromptTemplate([\n",
    "            (\"system\", \"\"\"\n",
    "             \n",
    "            아래의 코드와 제목, 요약을 참고하여 질의에 대해 답변합니다.\n",
    "            절대 코드에 대해 설명하지마세요.\n",
    "            독자는 프로그래머가 아닙니다.\n",
    "            항상 출력되는 값을 기준으로 설명합니다.\n",
    "            숫자가 매우 중요합니다. 숫자에 대한 정보를 잊지 마세요.\n",
    "            데이터 분석과 관련된 코드가 입력된다면 항상 인사이트를 포함하세요.\n",
    "\n",
    "            제목 : {title}\n",
    "            요약 : {summary}\n",
    "\n",
    "            코드 : {code}\n",
    "            \"\"\"),\n",
    "            (\"human\", \"{query}\")\n",
    "        ])        \n",
    "        \n",
    "        chain = prompt | llm\n",
    "        \n",
    "        answer = chain.invoke({\n",
    "            \"title\" : title,\n",
    "            \"summary\" : summary,\n",
    "            \"code\" : state[\"code\"],\n",
    "            \"query\" : state[\"messages\"][-1]\n",
    "        })\n",
    "\n",
    "        return {\"messages\" : answer}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pretty_print(state:State):\n",
    "\n",
    "    print(f\"\\n\\n===== Result =====\\n\\n\")\n",
    "\n",
    "    print(state[\"messages\"][-1].content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def select(state:State):\n",
    "    \"\"\"\n",
    "    단순한 분기점의 역할\n",
    "    현재 상태를 반환합니다.\n",
    "    \"\"\"\n",
    "    return state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph_builder = StateGraph(State)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 노드를 생성해주세요.\n",
    "\n",
    "\n",
    "\n",
    "# 엣지를 연결해주세요.\n",
    "\n",
    "graph_builder.add_conditional_edges(START,\n",
    "                                    Discriminate,\n",
    "                                    {\n",
    "                                    \"yes\":\"select\",\n",
    "                                     \"no\":\"response\"\n",
    "                                     }\n",
    "                                     )\n",
    "graph_builder.add_conditional_edges(\"select\",\n",
    "                                    Judgement,\n",
    "                                    {\n",
    "                                    \"tool\":\"create_code\",\n",
    "                                     \"llm\":\"response\"\n",
    "                                     }\n",
    "                                     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph_builder.add_node(\"select\", select)\n",
    "graph_builder.add_node(\"create_code\", create_code)\n",
    "graph_builder.add_node(\"execute_code\", execute_code)\n",
    "graph_builder.add_node(\"response\", response)\n",
    "graph_builder.add_node(\"code_response\", code_response)\n",
    "graph_builder.add_node(\"pretty_print\", pretty_print)\n",
    "\n",
    "\n",
    "graph_builder.add_conditional_edges(START,\n",
    "                                    Discriminate,\n",
    "                                    {\n",
    "                                    \"yes\":\"select\",\n",
    "                                     \"no\":\"response\"\n",
    "                                     }\n",
    "                                     )\n",
    "graph_builder.add_conditional_edges(\"select\",\n",
    "                                    Judgement,\n",
    "                                    {\n",
    "                                    \"tool\":\"create_code\",\n",
    "                                     \"llm\":\"response\"\n",
    "                                     }\n",
    "                                     )\n",
    "graph_builder.add_edge(\"create_code\", \"execute_code\")\n",
    "graph_builder.add_edge(\"execute_code\", \"code_response\")\n",
    "graph_builder.add_edge(\"code_response\", \"pretty_print\")\n",
    "graph_builder.add_edge(\"response\", \"pretty_print\")\n",
    "graph_builder.add_edge(\"pretty_print\", END);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "memory = MemorySaver()\n",
    "\n",
    "graph = graph_builder.compile(checkpointer=memory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = RunnableConfig(recursion_limit=10, configurable={\"thread_id\": \"1234\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = graph.stream({\"messages\": (\"user\",\"생존자의 비율 시각화하고 인사이트 제공해줘.\")}, config=config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for step in result:\n",
    "    for k,v in step.items():\n",
    "        print(f\"\\n\\n=== {k} ===\\n\\n\")\n",
    "        try:\n",
    "            v[\"messages\"][-1].pretty_print()\n",
    "        except:   \n",
    "            pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = graph.invoke({\"messages\":(\"user\",\"아까 내가 질문했던 내용 다시 알려줘\")}, config=config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = graph.invoke({\"messages\":(\"user\",\"아까 물어봤던 숫자들 다 더하면 몇인지 알려줘\")}, config=config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = \"./data/athlete_events.csv\"\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "tool = PythonAstREPLTool(name=\"python_repl_ast\", \n",
    "                        description=\"Python Code interpreter\",\n",
    "                        locals={\"df\":df})    \n",
    "\n",
    "title, summary = create_title_summary(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"제목 : \", title)\n",
    "print()\n",
    "print(\"요약 : \", summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = RunnableConfig(recursion_limit=10, configurable={\"thread_id\": \"1004\"})\n",
    "\n",
    "result = graph.stream({\"messages\":(\"user\", \"이 데이터셋은 어떤 데이터셋이야?\")}, config=config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for step in result:\n",
    "    for k,v in step.items():\n",
    "        print(f\"\\n\\n=== {k} ===\\n\\n\")\n",
    "        try:\n",
    "            v[\"messages\"][-1].pretty_print()\n",
    "        except:   \n",
    "            pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = graph.invoke({\"messages\":(\"user\", \"가장 많이 출전한 나라는 어디야?\")}, config=config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = graph.invoke({\"messages\":(\"user\", \"선수들의 평균 체중은 어떻게 돼?\")}, config=config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = graph.invoke({\"messages\":(\"user\", \"키와 체중, 그리고 메달 획득과의 상관관계를 보고 싶어. 그려줘\")}, config=config)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Modulabs",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
